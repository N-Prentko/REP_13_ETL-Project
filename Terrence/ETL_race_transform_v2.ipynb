{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETL Project - TRANSFORM\n",
    "## Terrence Cummings\n",
    "Data: Race mix of Minneapolis neighborhoods scraped from mncompass.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import requests\n",
    "import pymongo\n",
    "from splinter import Browser\n",
    "from selenium import webdriver\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "import datetime\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from sqlalchemy import create_engine\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in CSV's from Extract\n",
    "cmnty_links_df=pd.read_csv('cmnty_links.csv')\n",
    "nbhd_links_df=pd.read_csv('nbhd_links.csv')\n",
    "cmnty_race_df=pd.read_csv('cmnty_race.csv')\n",
    "nbhd_race_df=pd.read_csv('nbhd_race.csv')\n",
    "cmnty_keys_df=pd.read_csv('cmnty_keys.csv')\n",
    "nbhd_keys_df=pd.read_csv('nbhd_keys.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add community key to neighborhood key table to use as a foreign key\n",
    "nbhd_keys_df = nbhd_keys_df.merge(cmnty_keys_df, how='left', left_on='COMMUNITY', right_on='COMMUNITY')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create initial table of MSP neighborhoods (rows) and race mix (columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some figures from the scraped table show the word 'suppressed'. Replace with NaN for subsequent handling.\n",
    "nbhd_race_df = nbhd_race_df.replace('suppressed', np.nan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert population count text to numbers\n",
    "nbhd_race_df['white_cnt'] = nbhd_race_df['white_cnt'].str.replace(',', '').astype(float)\n",
    "nbhd_race_df['black_cnt'] = nbhd_race_df['black_cnt'].str.replace(',', '').astype(float)\n",
    "nbhd_race_df['native_cnt'] = nbhd_race_df['native_cnt'].str.replace(',', '').astype(float)\n",
    "nbhd_race_df['asian_cnt'] = nbhd_race_df['asian_cnt'].str.replace(',', '').astype(float)\n",
    "nbhd_race_df['other_cnt'] = nbhd_race_df['other_cnt'].str.replace(',', '').astype(float)\n",
    "nbhd_race_df['two_or_more_cnt'] = nbhd_race_df['two_or_more_cnt'].str.replace(',', '').astype(float)\n",
    "nbhd_race_df['hispanic_cnt'] = nbhd_race_df['hispanic_cnt'].str.replace(',', '').astype(float)\n",
    "nbhd_race_df['of_color_cnt'] = nbhd_race_df['of_color_cnt'].str.replace(',', '').astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert population percentage text to numbers\n",
    "nbhd_race_df['white_pct'] = nbhd_race_df['white_pct'].str.replace('%', '').astype(float)/100\n",
    "nbhd_race_df['black_pct'] = nbhd_race_df['black_pct'].str.replace('%', '').astype(float)/100\n",
    "nbhd_race_df['native_pct'] = nbhd_race_df['native_pct'].str.replace('%', '').astype(float)/100\n",
    "nbhd_race_df['asian_pct'] = nbhd_race_df['asian_pct'].str.replace('%', '').astype(float)/100\n",
    "nbhd_race_df['other_pct'] = nbhd_race_df['other_pct'].str.replace('%', '').astype(float)/100\n",
    "nbhd_race_df['two_or_more_pct'] = nbhd_race_df['two_or_more_pct'].str.replace('%', '').astype(float)/100\n",
    "nbhd_race_df['hispanic_pct'] = nbhd_race_df['hispanic_pct'].str.replace('%', '').astype(float)/100\n",
    "nbhd_race_df['of_color_pct'] = nbhd_race_df['of_color_pct'].str.replace('%', '').astype(float)/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop ECCO neighborhood due to no data\n",
    "nbhd_race_df.drop([11], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbhd_race_df.loc[nbhd_race_df['of_color_cnt'].isnull(),'of_color_cnt'] = nbhd_race_df['white_cnt']/nbhd_race_df['white_pct']-nbhd_race_df['white_cnt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add total population estimate for each neighborood based on the white count and percentage.\n",
    "\n",
    "nbhd_race_df['total_cnt']=nbhd_race_df['white_cnt']+nbhd_race_df['of_color_cnt']\n",
    "nbhd_race_df['of_color_pct']=nbhd_race_df['of_color_cnt']/nbhd_race_df['total_cnt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get rid of counts. Not needed when have Total Count and percentages\n",
    "nbhd_race_df=nbhd_race_df.drop(['white_cnt', 'black_cnt', 'native_cnt', 'asian_cnt','other_cnt','two_or_more_cnt','hispanic_cnt','of_color_cnt','URL'], axis = 1) \n",
    "\n",
    "#Add the neighborhood and community keys\n",
    "nbhd_race_df = nbhd_race_df.merge(nbhd_keys_df, left_on='neighborhood', right_on='neighborhood_url')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reorder columns for presentability. At this stage have a table with all neighborhoods and races, but with a lot of NaN's that needed to be reconciled.\n",
    "orig_nbhd_race_df = nbhd_race_df[['NBHD_KEY','total_cnt','white_pct','black_pct','native_pct','asian_pct','other_pct','two_or_more_pct','hispanic_pct','of_color_pct']]\n",
    "\n",
    "orig_nbhd_race_df.rename(columns = {'NBHD_KEY':'neighborhood_id'}, inplace = True) \n",
    "\n",
    "final_nbhd_race_df=orig_nbhd_race_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create table of MSP communities (rows) and race mix (columns). This will be used to backfill missing neighborhood-level data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the few 'suppressed' data to 0 as immaterial. \n",
    "cmnty_race_df['community'] = cmnty_race_df['community'].str.upper()\n",
    "cmnty_race_df = cmnty_race_df.replace('suppressed', np.nan)\n",
    "#cmnty_race_df = cmnty_race_df.replace(np.nan, '0', regex=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert race population count text to numbers.\n",
    "cmnty_race_df['white_cnt'] = cmnty_race_df['white_cnt'].str.replace(',', '').astype(float)\n",
    "cmnty_race_df['black_cnt'] = cmnty_race_df['black_cnt'].str.replace(',', '').astype(float)\n",
    "cmnty_race_df['native_cnt'] = cmnty_race_df['native_cnt'].str.replace(',', '').astype(float)\n",
    "cmnty_race_df['asian_cnt'] = cmnty_race_df['asian_cnt'].str.replace(',', '').astype(float)\n",
    "cmnty_race_df['other_cnt'] = cmnty_race_df['other_cnt'].str.replace(',', '').astype(float)\n",
    "cmnty_race_df['two_or_more_cnt'] = cmnty_race_df['two_or_more_cnt'].str.replace(',', '').astype(float)\n",
    "cmnty_race_df['hispanic_cnt'] = cmnty_race_df['hispanic_cnt'].str.replace(',', '').astype(float)\n",
    "cmnty_race_df['of_color_cnt'] = cmnty_race_df['of_color_cnt'].str.replace(',', '').astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert race population percentages to numbers\n",
    "cmnty_race_df['white_pct'] = cmnty_race_df['white_pct'].str.replace('%', '').astype(float)/100\n",
    "cmnty_race_df['black_pct'] = cmnty_race_df['black_pct'].str.replace('%', '').astype(float)/100\n",
    "cmnty_race_df['native_pct'] = cmnty_race_df['native_pct'].str.replace('%', '').astype(float)/100\n",
    "cmnty_race_df['asian_pct'] = cmnty_race_df['asian_pct'].str.replace('%', '').astype(float)/100\n",
    "cmnty_race_df['other_pct'] = cmnty_race_df['other_pct'].str.replace('%', '').astype(float)/100\n",
    "cmnty_race_df['two_or_more_pct'] = cmnty_race_df['two_or_more_pct'].str.replace('%', '').astype(float)/100\n",
    "cmnty_race_df['hispanic_pct'] = cmnty_race_df['hispanic_pct'].str.replace('%', '').astype(float)/100\n",
    "cmnty_race_df['of_color_pct'] = cmnty_race_df['of_color_pct'].str.replace('%', '').astype(float)/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a dicationary to map the scraped community names to the official community names\n",
    "cmnty_dict = {'CALHOUN-ISLES': 'CALHOUN-ISLE', 'CAMDEN':'CAMDEN', 'CENTRAL': 'CENTRAL', 'LONGFELLOW': 'LONGFELLOW', 'NEAR-NORTH': 'NEAR NORTH', 'NOKOMIS':'NOKOMIS', 'NORTHEAST':'NORTHEAST', 'PHILLIPS': 'PHILLIPS', 'POWDERHORN': 'POWDERHORN', 'SOUTHWEST':'SOUTHWEST', 'UNIVERSITY':'UNIVERSITY'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replaced scraped community names with official community names\n",
    "cmnty_race_df = cmnty_race_df.replace({\"community\": cmnty_dict})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add community keys to the community race table\n",
    "cmnty_race_df = cmnty_race_df.merge(cmnty_keys_df, how='left', left_on='community', right_on='COMMUNITY')\n",
    "del cmnty_race_df['COMMUNITY']\n",
    "\n",
    "#Add total population estimate for each community based on the white count and percentage.\n",
    "cmnty_race_df['total_cnt']=round(cmnty_race_df['white_cnt']/cmnty_race_df['white_pct'],0)\n",
    "\n",
    "#Drop unnecssary columns\n",
    "cmnty_race_df=cmnty_race_df.drop(['white_cnt', 'black_cnt', 'native_cnt', 'asian_cnt','other_cnt','two_or_more_cnt','hispanic_cnt','of_color_cnt','URL'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleanup column order and names\n",
    "orig_cmnty_race_df = cmnty_race_df[['CMNTY_KEY','total_cnt','white_pct','black_pct','native_pct','asian_pct','other_pct','two_or_more_pct','hispanic_pct','of_color_pct']]\n",
    "\n",
    "orig_cmnty_race_df.rename(columns = {'CMNTY_KEY':'community_id'}, inplace = True) \n",
    "final_cmnty_race_df=orig_cmnty_race_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CREATE FINAL TABLES AND LOAD INTO POSTGRESQL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write the final neighborhood and community race mix tables to csv's\n",
    "final_nbhd_race_df.to_csv('../target_files/nbhd_race_sql.csv')\n",
    "final_cmnty_race_df.to_csv('../target_files/cmnty_race_sql.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "host = \"localhost\"\n",
    "user = \"postgres\"\n",
    "port = \"5432\"\n",
    "passwd = \"hawkeyes\"\n",
    "db = \"REP_13_ETL_Project\"\n",
    "\n",
    "engine = create_engine(f'postgresql://{user}:{passwd}@{host}:{port}/{db}')\n",
    "connection = engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "communities_df=pd.read_csv('../target_files/MLPS_Communities.csv')\n",
    "neighorhoods_df=pd.read_csv('../target_files/MLPS_Neighborhoods.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_nbhd_race_df.to_sql('NEIGHBORHOOD_RACE', con=connection, if_exists = 'append', index=False)\n",
    "final_cmnty_race_df.to_sql('COMMUNITY_RACE', con=connection, if_exists = 'append', index=False)\n",
    "communities_df.to_sql('COMMUNITY', con=connection, if_exists = 'append', index=False)\n",
    "neighorhoods_df.to_sql('NEIGHBORHOOD',con=connection, if_exists = 'append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python361064bitpythondatacondaab47c43dfe824d4eb95e9e8f15b48370",
   "display_name": "Python 3.6.10 64-bit ('PythonData': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}